{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from CBHG import CBHGModel\n",
    "from diacritizer import Diacritizer\n",
    "from dataset import DiacriticsDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset_path = 'test_no_diacritics.txt'\n",
    "test_dataset_path = 'dataset/sample_test_no_diacritics.txt'\n",
    "model_path = 'models/CBHG_EP20_BS256.pth'\n",
    "# input_csv_path = 'test_set_without_labels.csv'\n",
    "output_csv_path = 'output/labels.csv'\n",
    "test_dataset_diacritized_path = 'output/diacritized.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DiacriticsDataset()\n",
    "test_dataset.load(test_dataset_path, train=False)\n",
    "\n",
    "inputs = test_dataset.character_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBHGModel(\n",
       "  (embedding): Embedding(37, 512)\n",
       "  (prenet): Prenet(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (cbhg): CBHG(\n",
       "    (relu): ReLU()\n",
       "    (conv1d_banks): ModuleList(\n",
       "      (0): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (2): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (3): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (4): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (5): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(6,), stride=(1,), padding=(3,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (6): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (7): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(8,), stride=(1,), padding=(4,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (8): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (9): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(10,), stride=(1,), padding=(5,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (10): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (11): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(12,), stride=(1,), padding=(6,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (12): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(13,), stride=(1,), padding=(6,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (13): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(14,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (14): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (15): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(256, 256, kernel_size=(16,), stride=(1,), padding=(8,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (max_pool1d): MaxPool1d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (conv1d_projections): ModuleList(\n",
       "      (0): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(4096, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (1): BatchNormConv1d(\n",
       "        (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (pre_highway): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (highways): ModuleList(\n",
       "      (0-3): 4 x Highway(\n",
       "        (H): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (T): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (gru): GRU(256, 512, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (post_cbhg_layers): ModuleList(\n",
       "    (0): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (projections): Linear(in_features=512, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CBHGModel(\n",
    "    inp_vocab_size = 37,\n",
    "    targ_vocab_size = 15,\n",
    ")\n",
    "\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "diacritics = torch.argmax(outputs['diacritics'], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_pad = inputs != test_dataset.pad_char\n",
    "output_diacritics = diacritics[mask_no_pad]\n",
    "\n",
    "df = pd.DataFrame(output_diacritics.numpy(), columns=[\"label\"])\n",
    "df = df.rename_axis('ID').reset_index()\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_dataset_path, 'r', encoding='utf-8') as file:\n",
    "    corpus = file.read()\n",
    "    \n",
    "diacritizer = Diacritizer()\n",
    "diacritized_corpus = diacritizer.diacritize(corpus, output_diacritics)\n",
    "\n",
    "with open(test_dataset_diacritized_path, 'w', encoding='utf-8') as file:\n",
    "    corpus = file.write(diacritized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
