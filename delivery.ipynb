{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from CBHG import CBHGModel\n",
    "from diacritizer import Diacritizer\n",
    "from dataset import DiacriticsDataset\n",
    "import pandas as pd\n",
    "from baseline import BaseLineModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset_path = 'test_no_diacritics.txt'\n",
    "test_dataset_path = 'dataset/test_no_diacritics.txt'\n",
    "model_path = 'models/CBHG_EP20_BS256.pth'\n",
    "# input_csv_path = 'test_set_without_labels.csv'\n",
    "output_csv_path = 'output/labels.csv'\n",
    "test_dataset_diacritized_path = 'output/diacritized.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBHGModel(\n",
      "  (embedding): Embedding(37, 512)\n",
      "  (prenet): Prenet(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (cbhg): CBHG(\n",
      "    (relu): ReLU()\n",
      "    (conv1d_banks): ModuleList(\n",
      "      (0): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (1): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(2,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (2): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (3): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(2,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (4): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (5): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(6,), stride=(1,), padding=(3,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (6): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (7): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(8,), stride=(1,), padding=(4,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (8): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (9): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(10,), stride=(1,), padding=(5,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (10): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (11): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(12,), stride=(1,), padding=(6,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (12): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(13,), stride=(1,), padding=(6,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (13): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(14,), stride=(1,), padding=(7,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (14): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (15): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(256, 256, kernel_size=(16,), stride=(1,), padding=(8,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (max_pool1d): MaxPool1d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (conv1d_projections): ModuleList(\n",
      "      (0): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(4096, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (1): BatchNormConv1d(\n",
      "        (conv1d): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "        (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (pre_highway): Linear(in_features=256, out_features=256, bias=False)\n",
      "    (highways): ModuleList(\n",
      "      (0-3): 4 x Highway(\n",
      "        (H): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (T): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (relu): ReLU()\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (gru): GRU(256, 512, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (post_cbhg_layers): ModuleList(\n",
      "    (0): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (projections): Linear(in_features=512, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DiacriticsDataset()\n",
    "train_dataset.load('dataset/train.txt')\n",
    "\n",
    "model_CBHG = CBHGModel(\n",
    "    inp_vocab_size=len(train_dataset.arabic_letters) + 1,\n",
    "    targ_vocab_size=len(train_dataset.diacritic_classes),\n",
    ")\n",
    "print(model_CBHG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3955 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# # train the model on a small batch to test the code\n",
    "model_CBHG.train_(train_dataset)\n",
    "# save the model\n",
    "torch.save(model_CBHG.state_dict(),'models/CBHG_EP10_BS16_LR0.0009.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:14<00:00, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9694641736870407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9694641736870407"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "# evaluate the model\n",
    "test_dataset = DiacriticsDataset()\n",
    "test_dataset.load('dataset/val.txt')\n",
    "# model_CBHG.eval()\n",
    "\n",
    "def evaluate(model, test_dataset, batch_size=16):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set.\n",
    "    Args:\n",
    "        test_dataset (torch.utils.data.Dataset): The test set.\n",
    "        batch_size (int): The batch size.\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    # Create a data loader from the test set\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # GPU Configuration\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "      model = model.cuda()\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for data in tqdm(test_loader):\n",
    "            # Get the inputs\n",
    "            inputs, labels = data[0], data[1]\n",
    "            inputs = inputs.to(torch.long)\n",
    "            labels = labels.to(torch.long)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # (5) move the train label to the device\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model.forward(inputs)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            acc = (torch.argmax(outputs['diacritics'],dim=-1) == labels).sum().item()\n",
    "            total += acc\n",
    "    total /= (len(test_dataset) * test_dataset[0][0].shape[0])\n",
    "\n",
    "    print(f'\\nTest Accuracy: {total}')\n",
    "    return total\n",
    "\n",
    "evaluate(model_CBHG,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded model\n",
    "model_CBHG_loaded = CBHGModel(\n",
    "    inp_vocab_size=37,\n",
    "    targ_vocab_size=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'models/CBHG_val_EP5_BS32_LR0.001.pthmodel_CBHG_loaded.load_state_dict(torch.load('))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_CBHG_loaded,test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DiacriticsDataset()\n",
    "test_dataset.load(test_dataset_path, train=False)\n",
    "\n",
    "inputs = test_dataset.character_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CBHGModel(\n",
    "#     inp_vocab_size = 37,\n",
    "#     targ_vocab_size = 15,\n",
    "# )\n",
    "\n",
    "# state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_CBHG.eval()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    model_CBHG = model_CBHG.cuda()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = model_CBHG(inputs)\n",
    "diacritics = torch.argmax(outputs['diacritics'], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_pad = inputs != test_dataset.pad_char\n",
    "output_diacritics = diacritics[mask_no_pad]\n",
    "output_diacritics = output_diacritics.cpu()\n",
    "\n",
    "df = pd.DataFrame(output_diacritics.numpy(), columns=[\"label\"])\n",
    "df = df.rename_axis('ID').reset_index()\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_dataset_path, 'r', encoding='utf-8') as file:\n",
    "    corpus = file.read()\n",
    "    \n",
    "diacritizer = Diacritizer()\n",
    "diacritized_corpus = diacritizer.diacritize(corpus, output_diacritics)\n",
    "\n",
    "with open(test_dataset_diacritized_path, 'w', encoding='utf-8') as file:\n",
    "    corpus = file.write(diacritized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
